{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of Y0 vs epsilon 1.0000000556147863 0.06913220911972986\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiple_factor import DGP2, Inferece2\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import statsmodels.api as sm\n",
    "from nbpmatching import match_tuple\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# load covariates data\n",
    "data = pd.read_csv(\"FactorialData/educationData2008.csv\")\n",
    "cols = ['Total']\n",
    "cols += list(data.iloc[:,26:32].columns)\n",
    "cols += list(data.iloc[:,34:36].columns)\n",
    "cols += ['teachers']\n",
    "covariates = data[cols].to_numpy()\n",
    "covariates = covariates/np.std(covariates,axis=0)\n",
    "covariates = covariates - np.mean(covariates,axis=0)\n",
    "# add a few noise to break the tie for S4\n",
    "covariates = covariates + 1e-5*np.random.normal(size=covariates.shape)\n",
    "regressor = -covariates[:,:-1]\n",
    "regressor = sm.add_constant(regressor)\n",
    "model = sm.OLS(covariates[:,-1], regressor)\n",
    "result = model.fit(cov_type='HC0')\n",
    "beta = result.params\n",
    "residuals = result.resid\n",
    "print(\"Variance of Y0 vs epsilon\",np.var(covariates[:,-1]), np.var(residuals))\n",
    "\n",
    "class DGP3(DGP2):\n",
    "    \n",
    "    def __init__(self, num_factor, Xdim, num_sample, X, tau=0, match_more=False, design='MT'):\n",
    "        self.total = X\n",
    "        self.covariates = X[:,:-1]\n",
    "        super().__init__(num_factor, num_sample, Xdim, tau, match_more, design)\n",
    "        \n",
    "    def generate_X(self):\n",
    "        idx = np.random.choice(len(self.total), self.n, replace=False)\n",
    "        total = self.total[idx]\n",
    "        X = total[:,:self.Xdim]\n",
    "        self.Y0 = total[:,-1]\n",
    "        return X\n",
    "    \n",
    "    def generate_D(self):\n",
    "        if self.design == 'MT':\n",
    "            self.tuple_idx = self.get_tuple_idx()\n",
    "            df = pd.DataFrame(self.tuple_idx)\n",
    "            idx = df.apply(lambda x:np.random.shuffle(x) or x, axis=1).to_numpy()\n",
    "            D = np.zeros((self.n, self.num_factor))\n",
    "            for c in range(idx.shape[1]):\n",
    "                D[idx[:,c]] = np.array([np.array(self.all_treatments[c])]*int(self.n/len(self.all_treatments)))\n",
    "        elif self.design == 'C':\n",
    "            D = np.array(self.all_treatments*int(self.n/len(self.all_treatments)))\n",
    "        elif self.design == 'S4':\n",
    "            self.tuple_idx = np.zeros(self.n)\n",
    "            D = np.zeros((self.n, self.num_factor))\n",
    "            #X = (self.X - .5).dot(np.linspace(1,2,self.Xdim))\n",
    "            X = self.X[:,np.random.choice(self.X.shape[1])]\n",
    "            idx_s1, idx_s2 = X <= np.quantile(X, .25), (X <= np.median(X)) & (np.quantile(X, .25) < X)\n",
    "            idx_s3, idx_s4 = (X <= np.quantile(X, .75)) & (np.median(X) < X), np.quantile(X, .75) < X\n",
    "            D[idx_s1] = np.array(self.all_treatments*int(self.n/len(self.all_treatments)/4))\n",
    "            D[idx_s2] = np.array(self.all_treatments*int(self.n/len(self.all_treatments)/4))\n",
    "            D[idx_s3] = np.array(self.all_treatments*int(self.n/len(self.all_treatments)/4))\n",
    "            D[idx_s4] = np.array(self.all_treatments*int(self.n/len(self.all_treatments)/4))\n",
    "            self.tuple_idx[idx_s2] = 1\n",
    "            self.tuple_idx[idx_s3] = 2\n",
    "            self.tuple_idx[idx_s4] = 3\n",
    "        elif self.design == 'RE':\n",
    "            a = chi2.ppf(.01**(1/self.num_factor), self.Xdim)\n",
    "            num_interaction = self.num_factor*(self.num_factor-1)/2\n",
    "            if num_interaction == 0:\n",
    "                b = 0\n",
    "            else:\n",
    "                b = chi2.ppf(.01**(1/num_interaction), self.Xdim)\n",
    "            Mf_max = 100\n",
    "            Mf_max_int = 100\n",
    "            D = np.array(self.all_treatments*int(self.n/len(self.all_treatments)))\n",
    "            while Mf_max > a or Mf_max_int > b:\n",
    "                idx = np.random.permutation(self.n)\n",
    "                D = D[idx]\n",
    "                #taux = np.array([np.mean(self.X[D[:,f]==1] - self.X[D[:,f]==0], axis=0) for f in range(self.num_factor)])\n",
    "                Mf_max = 0\n",
    "                # compute maximum imbalance in main effects\n",
    "                for f in range(self.num_factor):\n",
    "                    x_diff = np.mean(self.X[D[:,f]==1] - self.X[D[:,f]==0], axis=0)\n",
    "                    Mf = x_diff.dot(x_diff)*1*self.n/4\n",
    "                    if Mf > Mf_max:\n",
    "                        Mf_max = Mf\n",
    "                Mf_max_int = 0\n",
    "                # compute maximum imbalance in interaction effects\n",
    "                for f1 in range(self.num_factor):\n",
    "                    for f2 in range(f1+1, self.num_factor):\n",
    "                        x_diff = np.mean(self.X[D[:,f1]==D[:,f2]] - self.X[D[:,f1]!=D[:,f2]], axis=0)\n",
    "                        Mf_int = x_diff.dot(x_diff)*1*self.n/4\n",
    "                        if Mf_int > Mf_max_int:\n",
    "                            Mf_max_int = Mf_int\n",
    "        elif self.design == 'MP-B':\n",
    "            self.tuple_idx = match_tuple(self.X, 1)\n",
    "            df = pd.DataFrame(self.tuple_idx)\n",
    "            idx = df.apply(lambda x:np.random.shuffle(x) or x, axis=1).to_numpy()\n",
    "            D = np.zeros((self.n, self.num_factor))\n",
    "            D[idx[:,1],0] = 1\n",
    "            D[:,1:] = np.random.choice([0,1], size=(self.n, self.num_factor-1))\n",
    "        else:\n",
    "            raise ValueError(\"Design is not valid.\")\n",
    "        return D\n",
    "\n",
    "    def generate_Y(self):\n",
    "        eps = np.random.normal(0, np.sqrt(0.1), size=self.n)\n",
    "        if self.D.shape[1] > 1:\n",
    "            gamma = 2*self.D[:,1] - 1\n",
    "            #gamma = 1\n",
    "            Y = gamma*self.X.dot(beta[:self.Xdim]) \\\n",
    "                + (np.mean(self.D[:,1:],axis=1) + self.D[:,0])*self.tau + eps\n",
    "        else:\n",
    "            gamma = 1\n",
    "            Y = gamma*self.X.dot(beta[:self.Xdim]) \\\n",
    "                + self.D[:,0]*self.tau + eps\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_prob(X, num_factor, Xdim, sample_size, tau=0, ntrials=1000, more=False, design='MT'):\n",
    "    phi_tau = np.zeros(ntrials)\n",
    "    for i in range(ntrials):\n",
    "        dgp = DGP3(num_factor, Xdim, sample_size, X, tau, more, design)\n",
    "        Y, D, tuple_idx = dgp.Y, dgp.D, dgp.tuple_idx\n",
    "        inf = Inferece2(Y, D, tuple_idx, design)\n",
    "        phi_tau[i] = inf.phi_tau\n",
    "    return np.mean(phi_tau)\n",
    "\n",
    "def risk(X, num_factor, Xdim, sample_size, tau=0, ntrials=1000, more=False, design='MT'):\n",
    "    mse = np.zeros(ntrials)\n",
    "    for i in range(ntrials):\n",
    "        dgp = DGP3(num_factor, Xdim, sample_size, X, tau, more, design)\n",
    "        Y, D, tuple_idx = dgp.Y, dgp.D, dgp.tuple_idx\n",
    "        ate = np.mean(Y[D[:,0]==1]) - np.mean(Y[D[:,0]==0])\n",
    "        mse[i] = (ate - tau)**2\n",
    "    return np.mean(mse)\n",
    "\n",
    "def reject_prob_parrell(X, num_factor, Xdim, sample_size, tau=0, ntrials=1000, more=False, design='MT'):\n",
    "    if design == 'MT2':\n",
    "        more = True\n",
    "        design = 'MT'\n",
    "    def process(qk):\n",
    "        dgp = DGP3(num_factor, Xdim, sample_size, X, tau, more, design)\n",
    "        Y, D, tuple_idx = dgp.Y, dgp.D, dgp.tuple_idx\n",
    "        inf = Inferece2(Y, D, tuple_idx, design)\n",
    "        return inf.phi_tau\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    ret = Parallel(n_jobs=num_cores)(delayed(process)(i) for i in range(ntrials))\n",
    "    return np.mean(ret)\n",
    "\n",
    "def risk_parrell(X, num_factor, Xdim, sample_size, tau=0, ntrials=1000, more=False, design='MT'):\n",
    "    if design == 'MT2':\n",
    "        more = True\n",
    "        design = 'MT'\n",
    "    def process(qk):\n",
    "        dgp = DGP3(num_factor, Xdim, sample_size, X, tau, more, design)\n",
    "        Y, D, tuple_idx = dgp.Y, dgp.D, dgp.tuple_idx\n",
    "        ate = np.mean(Y[D[:,0]==1]) - np.mean(Y[D[:,0]==0])\n",
    "        return (ate - tau)**2\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    ret = Parallel(n_jobs=num_cores)(delayed(process)(i) for i in range(ntrials))\n",
    "    return np.mean(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011663872456536529\n",
      "0.0035302149949592836\n",
      "0.0027318713018196013\n",
      "0.0023949526350214565\n",
      "0.0\n",
      "0.1\n",
      "0.06\n"
     ]
    }
   ],
   "source": [
    "dimX = 9\n",
    "K = 5\n",
    "\n",
    "print(risk_parrell(covariates, K, dimX, 1280, 0, 100, design='MT'))\n",
    "print(risk_parrell(covariates, K, dimX, 1280, 0, 100, design='MP-B'))\n",
    "print(risk_parrell(covariates, K, dimX, 1280, 0, 100, design='S4'))\n",
    "print(risk_parrell(covariates, K, dimX, 1280, 0, 100, design='RE'))\n",
    "\n",
    "print(reject_prob_parrell(covariates, K, dimX, 1280, 0, 100, design='MT'))\n",
    "print(reject_prob_parrell(covariates, K, dimX, 1280, 0, 100, design='MT2'))\n",
    "print(reject_prob_parrell(covariates, K, dimX, 1280, 0, 100, design='S4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "K = 5\n",
    "dimX = 9\n",
    "\n",
    "designs = ['MT', 'MT2', 'C', 'S4', 'MP-B', 'RE']\n",
    "mse = [risk_parrell(covariates, K, dimX, 1280, 0, n, design=d) for d in designs]\n",
    "mse2 = [risk_parrell(covariates, K, dimX, 1280, 0.2, n, design=d) for d in designs]\n",
    "mser = mse/mse[0]\n",
    "mser2 = mse2/mse2[0]\n",
    "print(mser)\n",
    "print(mser2)\n",
    "\n",
    "designs = ['MT', 'MT2', 'C', 'S4']\n",
    "size = [reject_prob_parrell(covariates, K, dimX, 1280, 0, n, design=d) for d in designs]\n",
    "power = [reject_prob_parrell(covariates, K, dimX, 1280, 0.2, n, design=d) for d in designs]\n",
    "\n",
    "print(size)\n",
    "print(power)\n",
    "\n",
    "results = np.zeros((6,4))\n",
    "results[:,0] = mser\n",
    "results[:,1] = mser2\n",
    "results[:4,2] = size\n",
    "results[:4,3] = power\n",
    "\n",
    "pd.DataFrame(results).to_csv(\"sim_with_realdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   577.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:13:49</td>     <th>  Log-Likelihood:    </th> <td> -114.31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1376</td>      <th>  AIC:               </th> <td>   248.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1366</td>      <th>  BIC:               </th> <td>   300.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC0</td>       <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-2.901e-07</td> <td>    0.007</td> <td>-4.09e-05</td> <td> 1.000</td> <td>   -0.014</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.9808</td> <td>    0.016</td> <td>  -60.608</td> <td> 0.000</td> <td>   -1.012</td> <td>   -0.949</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0371</td> <td>    0.054</td> <td>    0.692</td> <td> 0.489</td> <td>   -0.068</td> <td>    0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    2.9176</td> <td>    3.175</td> <td>    0.919</td> <td> 0.358</td> <td>   -3.306</td> <td>    9.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    2.5978</td> <td>    2.836</td> <td>    0.916</td> <td> 0.360</td> <td>   -2.961</td> <td>    8.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.6750</td> <td>    1.822</td> <td>    0.919</td> <td> 0.358</td> <td>   -1.897</td> <td>    5.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    1.8927</td> <td>    2.151</td> <td>    0.880</td> <td> 0.379</td> <td>   -2.322</td> <td>    6.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.0379</td> <td>    0.007</td> <td>   -5.354</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0045</td> <td>    0.007</td> <td>    0.637</td> <td> 0.524</td> <td>   -0.009</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.1818</td> <td>    0.011</td> <td>  -16.349</td> <td> 0.000</td> <td>   -0.204</td> <td>   -0.160</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>41.509</td> <th>  Durbin-Watson:     </th> <td>   1.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  94.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.114</td> <th>  Prob(JB):          </th> <td>3.59e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.261</td> <th>  Cond. No.          </th> <td>1.15e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC0)<br/>[2] The condition number is large, 1.15e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.931\n",
       "Model:                            OLS   Adj. R-squared:                  0.930\n",
       "Method:                 Least Squares   F-statistic:                     577.2\n",
       "Date:                Thu, 09 Mar 2023   Prob (F-statistic):               0.00\n",
       "Time:                        14:13:49   Log-Likelihood:                -114.31\n",
       "No. Observations:                1376   AIC:                             248.6\n",
       "Df Residuals:                    1366   BIC:                             300.9\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:                  HC0                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -2.901e-07      0.007  -4.09e-05      1.000      -0.014       0.014\n",
       "x1            -0.9808      0.016    -60.608      0.000      -1.012      -0.949\n",
       "x2             0.0371      0.054      0.692      0.489      -0.068       0.142\n",
       "x3             2.9176      3.175      0.919      0.358      -3.306       9.141\n",
       "x4             2.5978      2.836      0.916      0.360      -2.961       8.157\n",
       "x5             1.6750      1.822      0.919      0.358      -1.897       5.247\n",
       "x6             1.8927      2.151      0.880      0.379      -2.322       6.108\n",
       "x7            -0.0379      0.007     -5.354      0.000      -0.052      -0.024\n",
       "x8             0.0045      0.007      0.637      0.524      -0.009       0.018\n",
       "x9            -0.1818      0.011    -16.349      0.000      -0.204      -0.160\n",
       "==============================================================================\n",
       "Omnibus:                       41.509   Durbin-Watson:                   1.467\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               94.151\n",
       "Skew:                           0.114   Prob(JB):                     3.59e-21\n",
       "Kurtosis:                       4.261   Cond. No.                     1.15e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC0)\n",
       "[2] The condition number is large, 1.15e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.931   \\\\\n",
      "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.930   \\\\\n",
      "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     577.2   \\\\\n",
      "\\textbf{Date:}             & Thu, 09 Mar 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
      "\\textbf{Time:}             &     14:13:56     & \\textbf{  Log-Likelihood:    } &   -114.31   \\\\\n",
      "\\textbf{No. Observations:} &        1376      & \\textbf{  AIC:               } &     248.6   \\\\\n",
      "\\textbf{Df Residuals:}     &        1366      & \\textbf{  BIC:               } &     300.9   \\\\\n",
      "\\textbf{Df Model:}         &           9      & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "               & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{const} &   -2.901e-07  &        0.007     & -4.09e-05  &         1.000        &       -0.014    &        0.014     \\\\\n",
      "\\textbf{x1}    &      -0.9808  &        0.016     &   -60.608  &         0.000        &       -1.012    &       -0.949     \\\\\n",
      "\\textbf{x2}    &       0.0371  &        0.054     &     0.692  &         0.489        &       -0.068    &        0.142     \\\\\n",
      "\\textbf{x3}    &       2.9176  &        3.175     &     0.919  &         0.358        &       -3.306    &        9.141     \\\\\n",
      "\\textbf{x4}    &       2.5978  &        2.836     &     0.916  &         0.360        &       -2.961    &        8.157     \\\\\n",
      "\\textbf{x5}    &       1.6750  &        1.822     &     0.919  &         0.358        &       -1.897    &        5.247     \\\\\n",
      "\\textbf{x6}    &       1.8927  &        2.151     &     0.880  &         0.379        &       -2.322    &        6.108     \\\\\n",
      "\\textbf{x7}    &      -0.0379  &        0.007     &    -5.354  &         0.000        &       -0.052    &       -0.024     \\\\\n",
      "\\textbf{x8}    &       0.0045  &        0.007     &     0.637  &         0.524        &       -0.009    &        0.018     \\\\\n",
      "\\textbf{x9}    &      -0.1818  &        0.011     &   -16.349  &         0.000        &       -0.204    &       -0.160     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lclc}\n",
      "\\textbf{Omnibus:}       & 41.509 & \\textbf{  Durbin-Watson:     } &    1.467  \\\\\n",
      "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &   94.151  \\\\\n",
      "\\textbf{Skew:}          &  0.114 & \\textbf{  Prob(JB):          } & 3.59e-21  \\\\\n",
      "\\textbf{Kurtosis:}      &  4.261 & \\textbf{  Cond. No.          } & 1.15e+03  \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{OLS Regression Results}\n",
      "\\end{center}\n",
      "\n",
      "Notes: \\newline\n",
      " [1] Standard Errors are heteroscedasticity robust (HC0) \\newline\n",
      " [2] The condition number is large, 1.15e+03. This might indicate that there are \\newline\n",
      " strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "table = result.summary().as_latex()\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total',\n",
       " 'nativeAmerican',\n",
       " 'black',\n",
       " 'latino',\n",
       " 'asian',\n",
       " 'white',\n",
       " 'male',\n",
       " 'stability',\n",
       " 'povertyRate',\n",
       " 'teachers']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb1c31993c61ea452a7bffd5740eb69b379c0a174f93c7698ebeb3ef9ab8ebf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
